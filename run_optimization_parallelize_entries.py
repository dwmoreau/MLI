"""
Current indexing rates

    - NO q2 ERROR
cF |  100% {'Not found': 0, 'Found': 208, 'Off by two': 0, 'Found explainers': 0}
cI |  100% {'Not found': 0, 'Found': 223, 'Off by two': 0, 'Found explainers': 0}
cP |  100% {'Not found': 0, 'Found': 463, 'Off by two': 1, 'Found explainers': 0}
hP | 99.8% {'Not found': 1, 'Found': 998, 'Off by two': 0, 'Found explainers': 1}
hR |  100% {'Not found': 0, 'Found': 1000, 'Off by two': 0, 'Found explainers': 0}
tI | 99.9% {'Not found': 1, 'Found': 999, 'Off by two': 0, 'Found explainers': 0}
tP | 99.6% {'Not found': 2, 'Found': 996, 'Off by two': 1, 'Found explainers': 1}
oC | 99.3% {'Not found': 4, 'Found': 993, 'Off by two': 0, 'Found explainers': 3}
oF |  100% {'Not found': 0, 'Found': 767, 'Off by two': 0, 'Found explainers': 0}
oI |  100% {'Not found': 0, 'Found': 496, 'Off by two': 0, 'Found explainers': 0}
oP | 99.8% {'Not found': 2, 'Found': 998, 'Off by two': 0, 'Found explainers': 0}
mC | 99.0% {'Not found': 4, 'Found': 990, 'Off by two': 1, 'Found explainers': 5}
mP | 99.2% {'Not found': 5, 'Found': 992, 'Off by two': 0, 'Found explainers': 3}
aP | 93.6% {'Not found': 32, 'Found': 936, 'Off by two': 0, 'Found explainers': 32}

    - 1X q2_error
cF | {'Not found': 1, 'Found': 207, 'Off by two': 0, 'Found explainers': 0}
cI | {'Not found': 0, 'Found': 223, 'Off by two': 0, 'Found explainers': 0}
cP | {'Not found': 3, 'Found': 460, 'Off by two': 1, 'Found explainers': 0}
hP | {'Not found': 5, 'Found': 995, 'Off by two': 0, 'Found explainers': 0}
hR | {'Not found': 6, 'Found': 994, 'Off by two': 0, 'Found explainers': 0}
tI | {'Not found': 6, 'Found': 994, 'Off by two': 0, 'Found explainers': 0}
tP | {'Not found': 4, 'Found': 996, 'Off by two': 0, 'Found explainers': 0}
oC | {'Not found': 25, 'Found': 975, 'Off by two': 0, 'Found explainers': 0}
oF | {'Not found': 6, 'Found': 761, 'Off by two': 0, 'Found explainers': 0}
oI | {'Not found': 4, 'Found': 492, 'Off by two': 0, 'Found explainers': 0}
oP | {'Not found': 5, 'Found': 995, 'Off by two': 0, 'Found explainers': 0}
mC | {'Not found': 32, 'Found': 968, 'Off by two': 0, 'Found explainers': 0}
mP | {'Not found': 62, 'Found': 937, 'Off by two': 1, 'Found explainers': 0}
aP | {'Not found': 393, 'Found': 607, 'Off by two': 0, 'Found explainers': 0}

    -2X q2_error
cF | {'Not found': 4, 'Found': 204, 'Off by two': 0, 'Found explainers': 0}
cI | {'Not found': 8, 'Found': 213, 'Off by two': 2, 'Found explainers': 0}
cP | {'Not found': 36, 'Found': 425, 'Off by two': 3, 'Found explainers': 0}
hP | {'Not found': 26, 'Found': 974, 'Off by two': 0, 'Found explainers': 0}
hR | {'Not found': 30, 'Found': 970, 'Off by two': 0, 'Found explainers': 0}
tI | {'Not found': 28, 'Found': 972, 'Off by two': 0, 'Found explainers': 0}
tP | {'Not found': 45, 'Found': 955, 'Off by two': 0, 'Found explainers': 0}
oC | {'Not found': 87, 'Found': 912, 'Off by two': 1, 'Found explainers': 0}
oF | {'Not found': 34, 'Found': 733, 'Off by two': 0, 'Found explainers': 0}
oI | {'Not found': 40, 'Found': 456, 'Off by two': 0, 'Found explainers': 0}
oP | {'Not found': 18, 'Found': 981, 'Off by two': 1, 'Found explainers': 0}
mC | {'Not found': 147, 'Found': 849, 'Off by two': 4, 'Found explainers': 0}
mP | {'Not found': 292, 'Found': 705, 'Off by two': 3, 'Found explainers': 0}
aP | {'Not found': 803, 'Found': 197, 'Off by two': 0, 'Found explainers': 0}

    - 3x q2 ERROR
mC | {'Not found': 434, 'Found': 566, 'Off by two': 0, 'Found explainers': 0}
mP | {'Not found': 549, 'Found': 449, 'Off by two': 2, 'Found explainers': 0}
aP | 

    -4X q2_error
cF | {'Not found': 38, 'Found': 169, 'Off by two': 1, 'Found explainers': 0}
cI | {'Not found': 50, 'Found': 169, 'Off by two': 4, 'Found explainers': 0}
cP | {'Not found': 171, 'Found': 284, 'Off by two': 9, 'Found explainers': 0}
hP | {'Not found': 121, 'Found': 879, 'Off by two': 0, 'Found explainers': 0}
hR | {'Not found': 128, 'Found': 870, 'Off by two': 2, 'Found explainers': 0}
tI | {'Not found': 153, 'Found': 847, 'Off by two': 0, 'Found explainers': 0}
tP | {'Not found': 231, 'Found': 765, 'Off by two': 4, 'Found explainers': 0}
oC | {'Not found': 337, 'Found': 663, 'Off by two': 0, 'Found explainers': 0}
oF | {'Not found': 252, 'Found': 515, 'Off by two': 0, 'Found explainers': 0}
oI | {'Not found': 164, 'Found': 332, 'Off by two': 0, 'Found explainers': 0}
oP | {'Not found': 357, 'Found': 640, 'Off by two': 3, 'Found explainers': 0}
mC | {'Not found': 726, 'Found': 273, 'Off by two': 1, 'Found explainers': 0}
mP | {'Not found': 741, 'Found': 255, 'Off by two': 4, 'Found explainers': 0}
aP | {'Not found': 976, 'Found': 24, 'Off by two': 0, 'Found explainers': 0}

    -6X q2_error
cF | {'Not found': 92, 'Found': 115, 'Off by two': 1, 'Found explainers': 0}
cI | {'Not found': 90, 'Found': 118, 'Off by two': 15, 'Found explainers': 0}
cP | {'Not found': 264, 'Found': 188, 'Off by two': 12, 'Found explainers': 0}
hP | {'Not found': 306, 'Found': 692, 'Off by two': 2, 'Found explainers': 0}
hR | {'Not found': 307, 'Found': 692, 'Off by two': 1, 'Found explainers': 0}
tI | {'Not found': 388, 'Found': 611, 'Off by two': 1, 'Found explainers': 0}
tP | {'Not found': 494, 'Found': 504, 'Off by two': 2, 'Found explainers': 0}
oC | {'Not found': 634, 'Found': 362, 'Off by two': 4, 'Found explainers': 0}
oF | {'Not found': 497, 'Found': 269, 'Off by two': 1, 'Found explainers': 0}
oI | {'Not found': 299, 'Found': 197, 'Off by two': 0, 'Found explainers': 0}
oP | {'Not found': 755, 'Found': 238, 'Off by two': 7, 'Found explainers': 0}
mC | {'Not found': 938, 'Found': 62, 'Off by two': 0, 'Found explainers': 0}
mP | {'Not found': 937, 'Found': 63, 'Off by two': 0, 'Found explainers': 0}
aP |

    - 1X q2_error & 1 contaminant
cF | {'Not found': 28, 'Found': 147, 'Off by two': 33, 'Found explainers': 0}
cI | {'Not found': 44, 'Found': 173, 'Off by two': 6, 'Found explainers': 0}
cP | {'Not found': 72, 'Found': 386, 'Off by two': 6, 'Found explainers': 0}
hP | {'Not found': 10, 'Found': 990, 'Off by two': 0, 'Found explainers': 0}
hR | {'Not found': 9, 'Found': 991, 'Off by two': 0, 'Found explainers': 0}
tI | {'Not found': 12, 'Found': 987, 'Off by two': 1, 'Found explainers': 0}
tP | {'Not found': 6, 'Found': 994, 'Off by two': 0, 'Found explainers': 0}
oC | {'Not found': 49, 'Found': 948, 'Off by two': 3, 'Found explainers': 0}
oF | {'Not found': 15, 'Found': 752, 'Off by two': 0, 'Found explainers': 0}
oI | {'Not found': 13, 'Found': 483, 'Off by two': 0, 'Found explainers': 0}
oP | {'Not found': 69, 'Found': 929, 'Off by two': 2, 'Found explainers': 0}
mC | {'Not found': 137, 'Found': 862, 'Off by two': 1, 'Found explainers': 0}
mP | {'Not found': 221, 'Found': 769, 'Off by two': 10, 'Found explainers': 0}
aP | {'Not found': 633, 'Found': 367, 'Off by two': 0, 'Found explainers': 0}

    - 1X q2_error & 2 contaminants
cF | {'Not found': 52, 'Found': 121, 'Off by two': 35, 'Found explainers': 0}
cI | {'Not found': 56, 'Found': 154, 'Off by two': 13, 'Found explainers': 0}
cP | {'Not found': 147, 'Found': 301, 'Off by two': 16, 'Found explainers': 0}
hP | {'Not found': 11, 'Found': 988, 'Off by two': 1, 'Found explainers': 0}
hR | {'Not found': 17, 'Found': 983, 'Off by two': 0, 'Found explainers': 0}
tI | {'Not found': 27, 'Found': 973, 'Off by two': 0, 'Found explainers': 0}
tP | {'Not found': 17, 'Found': 981, 'Off by two': 2, 'Found explainers': 0}
oC | {'Not found': 123, 'Found': 876, 'Off by two': 1, 'Found explainers': 0}
oF | 
oI | 
oP | 
mC | {'Not found': 300, 'Found': 697, 'Off by two': 3, 'Found explainers': 0}
mP | {'Not found': 370, 'Found': 616, 'Off by two': 14, 'Found explainers': 0}
aP | {'Not found': 785, 'Found': 215, 'Off by two': 0, 'Found explainers': 0}

    - 1X q2_error & 3 contaminants
oC | 
oF | 
oI | 
oP | 
mC | {'Not found': 458, 'Found': 539, 'Off by two': 3, 'Found explainers': 0}
mP | {'Not found': 508, 'Found': 472, 'Off by two': 20, 'Found explainers': 0}
aP | {'Not found': 897, 'Found': 103, 'Off by two': 0, 'Found explainers': 0}

    - 1X q2_error & 4 contaminants
oC | 
oF | 
oI | 
oP | 
mC | {'Not found': 615, 'Found': 384, 'Off by two': 1, 'Found explainers': 0}
mP | {'Not found': 648, 'Found': 343, 'Off by two': 9, 'Found explainers': 0}
aP | {'Not found': 941, 'Found': 59, 'Off by two': 0, 'Found explainers': 0}

    - 1X q2_error & 5 contaminants
oC | 
oF | 
oI | 
oP | 
mC | {'Not found': 722, 'Found': 276, 'Off by two': 2, 'Found explainers': 0}
mP | {'Not found': 750, 'Found': 238, 'Off by two': 12, 'Found explainers': 0}
aP | {'Not found': 969, 'Found': 31, 'Off by two': 0, 'Found explainers': 0}

    - 1X q2_error & 6 contaminants
oC | 
oF | 
oI | 
oP | 
mC | {'Not found': 799, 'Found': 201, 'Off by two': 0, 'Found explainers': 0}
mP | {'Not found': 823, 'Found': 164, 'Off by two': 13, 'Found explainers': 0}
aP | {'Not found': 982, 'Found': 17, 'Off by two': 1, 'Found explainers': 0}

    - 1X q2_error & 1 contaminants & n_candidates
     1000 | 2000 | 3000 | 4000
cF |  146 |  205 |  206 |
cI |  173 |  221 |  222 |
cP |  383 |  448 |  457 |  459
      
    - 1X q2_error & 2 contaminants & n_candidates
     1000 | 2000 | 3000 | 4000
hP |  989 |  989 |
hR |  982 |  982 |
tI |  966 |  969 |
tP |  975 |  978 |

     3000 | 4000 | 5000 | 10000
oC |  872 |  866 |  878 |   883
oF |  
oI |  
oP |  853 |  859 |  859 |  868 

     5000 | 10000 |
mC |  689 | 696
mP |  600 | 577

     5000 | 10000 |
aP | 


    - NO q2 ERROR - Random unit cell generation
mC | {'Not found': 21, 'Found': 792, 'Off by two': 2, 'Found explainers': 185}
mP | {'Not found': 48, 'Found': 927, 'Off by two': 0, 'Found explainers': 25}
aP | {'Not found': 102, 'Found': 760, 'Off by two': 0, 'Found explainers': 138}

    - 1x q2 ERROR - Random unit cell generation
mC | {'Not found': 248, 'Found': 749, 'Off by two': 3, 'Found explainers': 0}
mP | {'Not found': 168, 'Found': 831, 'Off by two': 1, 'Found explainers': 0}
aP | {'Not found': 566, 'Found': 434, 'Off by two': 0, 'Found explainers': 0}

    - 2x q2 ERROR - Random unit cell generation
mC | {'Not found': 426, 'Found': 564, 'Off by two': 10, 'Found explainers': 0}
mP | {'Not found': 360, 'Found': 639, 'Off by two': 1, 'Found explainers': 0}
aP | {'Not found': 861, 'Found': 139, 'Off by two': 0, 'Found explainers': 0}

    - 3x q2 ERROR - Random unit cell generation
mC | {'Not found': 669, 'Found': 324, 'Off by two': 7, 'Found explainers': 0}
mP | {'Not found': 593, 'Found': 405, 'Off by two': 2, 'Found explainers': 0}
aP | {'Not found': 966, 'Found': 34, 'Off by two': 0, 'Found explainers': 0}

    - 4x q2 ERROR - Random unit cell generation
mC | {'Not found': 800, 'Found': 197, 'Off by two': 3, 'Found explainers': 0}
mP | {'Not found': 770, 'Found': 230, 'Off by two': 0, 'Found explainers': 0}
aP | {'Not found': 992, 'Found': 8, 'Off by two': 0, 'Found explainers': 0}

    - 6x q2 ERROR - Random unit cell generation
mC | {'Not found': 957, 'Found': 41, 'Off by two': 2, 'Found explainers': 0}
mP | {'Not found': 951, 'Found': 49, 'Off by two': 0, 'Found explainers': 0}
aP | {'Not found': 1000, 'Found': 0, 'Off by two': 0, 'Found explainers': 0}

    - 1x q2 ERROR & 1 contaminant- Random unit cell generation
mC | {'Not found': 343, 'Found': 650, 'Off by two': 7, 'Found explainers': 0}
mP | {'Not found': 302, 'Found': 690, 'Off by two': 8, 'Found explainers': 0}
aP | {'Not found': 726, 'Found': 274, 'Off by two': 0, 'Found explainers': 0}

    - 1x q2 ERROR & 2 contaminant- Random unit cell generation
mC | {'Not found': 449, 'Found': 545, 'Off by two': 6, 'Found explainers': 0}
mP | {'Not found': 422, 'Found': 570, 'Off by two': 8, 'Found explainers': 0}
aP | {'Not found': 817, 'Found': 183, 'Off by two': 0, 'Found explainers': 0}

    - 1x q2 ERROR & 3 contaminant- Random unit cell generation
mC | {'Not found': 541, 'Found': 453, 'Off by two': 6, 'Found explainers': 0}
mP | {'Not found': 520, 'Found': 468, 'Off by two': 12, 'Found explainers': 0}
aP | {'Not found': 905, 'Found': 95, 'Off by two': 0, 'Found explainers': 0}

    - 1x q2 ERROR & 4 contaminant- Random unit cell generation
mC | {'Not found': 656, 'Found': 344, 'Off by two': 0, 'Found explainers': 0}
mP | {'Not found': 638, 'Found': 356, 'Off by two': 6, 'Found explainers': 0}
aP | {'Not found': 943, 'Found': 57, 'Off by two': 0, 'Found explainers': 0}

    - 1x q2 ERROR & 5 contaminant- Random unit cell generation
mC | {'Not found': 735, 'Found': 263, 'Off by two': 2, 'Found explainers': 0}
mP | {'Not found': 719, 'Found': 272, 'Off by two': 9, 'Found explainers': 0}
aP | {'Not found': 951, 'Found': 49, 'Off by two': 0, 'Found explainers': 0}

    - 1x q2 ERROR & 6 contaminant- Random unit cell generation
mC | {'Not found': 790, 'Found': 209, 'Off by two': 1, 'Found explainers': 0}
mP | {'Not found': 781, 'Found': 208, 'Off by two': 11, 'Found explainers': 0}
aP | {'Not found': 978, 'Found': 22, 'Off by two': 0, 'Found explainers': 0}
"""
from mpi4py import MPI
import os
# This supresses the tensorflow message on import
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'
import numpy as np
import pandas as pd
import time

from Utilities import get_peak_generation_info
from UtilitiesOptimizer import get_cubic_optimizer
from UtilitiesOptimizer import get_hexagonal_optimizer
from UtilitiesOptimizer import get_monoclinic_optimizer
from UtilitiesOptimizer import get_orthorhombic_optimizer
from UtilitiesOptimizer import get_rhombohedral_optimizer
from UtilitiesOptimizer import get_tetragonal_optimizer
from UtilitiesOptimizer import get_triclinic_optimizer
from UtilitiesOptimizer import validate_candidate_known_bl


if __name__ == '__main__':
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    n_ranks = comm.Get_size()
    split_comm = comm.Split(color=rank, key=rank)

    #np.seterr(all='raise')

    load_data = True
    broadening_tag = '1'
    n_entries = 1000

    peak_generation_info = get_peak_generation_info()
    q2_error_params = 3 * peak_generation_info['q2_error_params']
    q2_broadening_params = peak_generation_info['broadening_params']
    n_contaminants = 0
    n_top_candidates = 20
    #bravais_lattices = ['cF', 'cI', 'cP', 'hP', 'hR', 'tI', 'tP', 'oC', 'oF', 'oI', 'oP', 'mC', 'mP', 'aP']
    bravais_lattices = ['aP']
    optimizer = dict.fromkeys(bravais_lattices)
    rng = np.random.default_rng(0)
    for bravais_lattice in bravais_lattices:
        if bravais_lattice in ['cF', 'cI', 'cP']:
            optimizer[bravais_lattice] = get_cubic_optimizer(bravais_lattice, broadening_tag, 1, split_comm)
        elif bravais_lattice in ['hP']:
            optimizer[bravais_lattice] = get_hexagonal_optimizer(bravais_lattice, broadening_tag, 1, split_comm)
        elif bravais_lattice in ['hR']:
            optimizer[bravais_lattice] = get_rhombohedral_optimizer(bravais_lattice, broadening_tag, 1, split_comm)
        elif bravais_lattice in ['tI', 'tP']:
            optimizer[bravais_lattice] = get_tetragonal_optimizer(bravais_lattice, broadening_tag, 1, split_comm)
        elif bravais_lattice in ['oC', 'oF', 'oI', 'oP']:
            optimizer[bravais_lattice] = get_orthorhombic_optimizer(bravais_lattice, broadening_tag, 1, split_comm)
        elif bravais_lattice in ['mC', 'mP']:
            optimizer[bravais_lattice] = get_monoclinic_optimizer(bravais_lattice, broadening_tag, 1, split_comm)
        elif bravais_lattice in ['aP']:
            optimizer[bravais_lattice] = get_triclinic_optimizer(bravais_lattice, broadening_tag, 1, split_comm)

    if rank == 0:
        if load_data:
            data = []
            read_columns = [
                'lattice_system',
                'bravais_lattice',
                'train',
                f'q2_{broadening_tag}',
                f'reindexed_h_{broadening_tag}',
                f'reindexed_k_{broadening_tag}',
                f'reindexed_l_{broadening_tag}',
                'reindexed_spacegroup_symbol_hm',
                'reindexed_unit_cell',
                ]
            drop_columns = [
                f'q2_{broadening_tag}',
                f'reindexed_h_{broadening_tag}',
                f'reindexed_k_{broadening_tag}',
                f'reindexed_l_{broadening_tag}',
                ]
            for bravais_lattice in bravais_lattices:
                n_peaks = 20
                if bravais_lattice in ['cF', 'cI', 'cP']:
                    n_peaks_contaminants = 10
                else:
                    n_peaks_contaminants = 20
                bravais_lattice_data = pd.read_parquet(
                    f'/Users/DWMoreau/MLI/data/GeneratedDatasets/dataset_{bravais_lattice}.parquet',
                    columns=read_columns
                    )
                bravais_lattice_data = bravais_lattice_data.loc[~bravais_lattice_data['train']]
                peaks = bravais_lattice_data[f'q2_{broadening_tag}']
                bravais_lattice_data = bravais_lattice_data.loc[peaks.apply(len) >= n_peaks]
                peaks = bravais_lattice_data[f'q2_{broadening_tag}']
                bravais_lattice_data = bravais_lattice_data.loc[peaks.apply(np.count_nonzero) >= n_peaks]
                q2 = np.zeros((bravais_lattice_data.shape[0], n_peaks + n_contaminants))
                hkl = np.zeros((bravais_lattice_data.shape[0], n_peaks + n_contaminants, 3))
                for entry_index in range(bravais_lattice_data.shape[0]):
                    q2[entry_index, :n_peaks] = np.array(bravais_lattice_data[f'q2_{broadening_tag}'].iloc[entry_index])[:n_peaks]
                    hkl[entry_index, :n_peaks, 0] = np.array(bravais_lattice_data[f'reindexed_h_{broadening_tag}'].iloc[entry_index])[:n_peaks]
                    hkl[entry_index, :n_peaks, 1] = np.array(bravais_lattice_data[f'reindexed_k_{broadening_tag}'].iloc[entry_index])[:n_peaks]
                    hkl[entry_index, :n_peaks, 2] = np.array(bravais_lattice_data[f'reindexed_l_{broadening_tag}'].iloc[entry_index])[:n_peaks]
                sigma_error = q2_error_params[0] + q2[:, :n_peaks] * q2_error_params[1]
                q2[:, :n_peaks] += rng.normal(loc=0, scale=sigma_error)
                q2[:, :n_peaks] = np.abs(q2[:, :n_peaks])
                breadth = q2_broadening_params[0] + q2_broadening_params[1] * q2[:, :n_peaks_contaminants]
                if n_contaminants > 0:
                    for entry_index in range(bravais_lattice_data.shape[0]):
                        status = True
                        while status:
                            q2_contaminants = rng.uniform(
                                low=0.5*q2[entry_index, 0],
                                high=q2[entry_index, n_peaks_contaminants - 1],
                                size=n_contaminants
                                )
                            difference = np.abs(
                                q2_contaminants[np.newaxis]
                                - q2[entry_index, :n_peaks_contaminants][:, np.newaxis]
                                ).min(axis=0)
                            status = np.any(difference[np.newaxis] < 0.5*breadth[entry_index][:, np.newaxis])

                        q2[entry_index, n_peaks:] = q2_contaminants
                        sort_indices = np.argsort(q2[entry_index])
                        q2[entry_index] = q2[entry_index, sort_indices]
                        hkl[entry_index, :, 0] = hkl[entry_index, sort_indices, 0]
                        hkl[entry_index, :, 1] = hkl[entry_index, sort_indices, 1]
                        hkl[entry_index, :, 2] = hkl[entry_index, sort_indices, 2]
                bravais_lattice_data['q2'] = list(q2)
                bravais_lattice_data['reindexed_hkl'] = list(hkl)
                bravais_lattice_data.drop(columns=drop_columns, inplace=True)
                data.append(bravais_lattice_data)
            data = pd.concat(data)
            if not n_entries is None and data.shape[0] > n_entries:
                data = data.iloc[:n_entries]
        for rank_index in range(1, n_ranks):
            comm.send(data.iloc[rank_index::n_ranks], dest=rank_index)
        data = data.iloc[0::n_ranks]
    else:
        data = comm.recv(source=0)

    n_entries = data.shape[0]
    report_counts = {
        'Not found': 0,
        'Found': 0,
        'Off by two': 0,
        'Found explainers': 0,
        }
    for entry_index in range(n_entries):
        entry = data.iloc[entry_index]
        unit_cell_true = np.array(entry['reindexed_unit_cell'])
        for bravais_lattice in bravais_lattices:
            start = time.time()
            optimizer[bravais_lattice].run(entry=entry, n_top_candidates=n_top_candidates)
            found = False
            off_by_two = False
            found_explainer = False
            #print(np.column_stack((
            #    optimizer[bravais_lattice].top_unit_cell,
            #    optimizer[bravais_lattice].top_M20,
            #    optimizer[bravais_lattice].top_spacegroup
            #    )))
            for candidate_index in range(optimizer[bravais_lattice].top_unit_cell.shape[0]):
                correct, off_by_two = validate_candidate_known_bl(
                    unit_cell_true=unit_cell_true,
                    unit_cell_pred=optimizer[bravais_lattice].top_unit_cell[candidate_index],
                    bravais_lattice_pred=bravais_lattice,
                    )
                if correct:
                    found = True
                if off_by_two:
                    off_by_two = True
                if np.any(optimizer[bravais_lattice].top_M20 > 1000):
                    found_explainer = True
            if found:
                report_counts['Found'] += 1
            elif off_by_two:
                report_counts['Off by two'] += 1
            elif found_explainer:
                report_counts['Found explainers'] += 1
            else:
                report_counts['Not found'] += 1
                #print()
                #print(entry)
                #print(np.column_stack((
                #    optimizer[bravais_lattice].top_unit_cell,
                #    optimizer[bravais_lattice].top_M20,
                #    optimizer[bravais_lattice].top_spacegroup
                #    )))
                #print()
            stop = time.time()
            #print(report_counts, rank, stop - start)
            #print()
    report_counts_gathered = comm.gather(report_counts, root=0)

    if rank == 0:
        report_counts_all = {
            'Not found': 0,
            'Found': 0,
            'Off by two': 0,
            'Found explainers': 0,
            }
        for rank_index in range(n_ranks):
            for key in report_counts_gathered[rank_index].keys():
                report_counts_all[key] += report_counts_gathered[rank_index][key]
        print(report_counts_all)
